{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6906cb04-0b79-4c3a-8e6e-bc324dc9f756",
   "metadata": {},
   "source": [
    "# 本节内容摘要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a9ab9-af14-4cd4-a05b-6345e4e05e2f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2.基础优化算法\n",
    "\n",
    "- **梯度下降**\n",
    "\n",
    "  - 当模型没有显示解的时候，应用梯度下降法逼近最优解。\n",
    "  - 梯度下降法的具体步骤：\n",
    "    - 挑选一个初始值$\\omega_0$\n",
    "    - 重复迭代参数，迭代公式为：$\\omega_t=\\omega_{t-1}-\\lambda\\frac{\\partial l}{\\partial\\omega_{t-1} } $\n",
    "      - **$-\\frac{\\partial l}{\\partial\\omega_{t-1}}$为函数值下降最快的方向，学习率$\\lambda$为学习步长。**\n",
    "  - 选择学习率\n",
    "    - 学习率$\\lambda$为学习步长，代表了沿负梯度方向走了多远，这是超参数（人为指定的的值，不是训练得到的）\n",
    "    - 学习率不能太大，也不能太小，需要选取适当。\n",
    "\n",
    "- **小批量随机梯度下降**\n",
    "\n",
    "  - 在整个训练集上算梯度太贵了\n",
    "\n",
    "    - 在实际应用中，很少直接应用梯度下降法，这是因为每次更新都需要计算训练集上所有的样本，耗费时间太长。\n",
    "    - 一个深度神经网络模型，迭代一次可能需要数分钟甚至数小时。\n",
    "\n",
    "  - 为了减少运算代价，我们可以随机采样b个样本$i_1,i_2,...,i_b$来近似损失，损失函数为：\n",
    "\n",
    "    ​\t$\\frac{1}{b}\\sum_{i\\in I_b}l(x_i,y_i,\\omega)$ , \n",
    "\n",
    "    其中**b是批量大小(batch size)，也是超参数**\n",
    "\n",
    "  - **选择批量大小**\n",
    "    \n",
    "    - b也不能太大：内存消耗增加；浪费计算资源，一个极端的情况是可能会重复选取很多差不多的样本，浪费计算资源\n",
    "    - b也不能太小：每次计算量太小，很难以并行，不能最大限度利用GPU资源\n",
    "\n",
    "- **总结**\n",
    "\n",
    "  - 梯度下降通过不断**沿着梯度反方向**更新参数求解\n",
    "  - 小批量随机梯度下降是深度学习默认的求解算法（简单，稳定）\n",
    "  - **两个重要的超参数：批量大小（batch size），学习率（lr）**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99f95e-5043-4d84-be12-44a4bf93c6c9",
   "metadata": {},
   "source": [
    "# 讲义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a63f3670-117f-4ceb-92bb-277c5bf01faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1100\"\n",
       "            height=\"600\"\n",
       "            src=\"../PPT/part-0_9.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1063720d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, IFrame\n",
    "\n",
    "# 使用IFrame将PDF文件嵌入到Notebook中\n",
    "pdf_path = \"../PPT/part-0_9.pdf\"\n",
    "display(IFrame(pdf_path, width=1100, height=600))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b9ec6e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 线性回归的简洁实现\n",
    "\n",
    "通过使用深度学习框架来简洁地实现\n",
    "线性回归模型\n",
    "生成数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c26b741f",
   "metadata": {
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = d2l.synthetic_data(true_w, true_b, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eda004",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "调用框架中现有的API来读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c6919b8",
   "metadata": {
    "origin_pos": 13,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0062, -0.8600],\n",
       "         [-0.5421,  0.5865],\n",
       "         [-0.2224,  0.3530],\n",
       "         [ 0.1049,  1.1843],\n",
       "         [-0.5222, -0.9637],\n",
       "         [ 0.7598,  1.0531],\n",
       "         [-0.1623, -0.3923],\n",
       "         [ 0.5898,  1.2558],\n",
       "         [-1.2157,  0.0183],\n",
       "         [-0.4795, -0.0923]]),\n",
       " tensor([[7.1272],\n",
       "         [1.1257],\n",
       "         [2.5582],\n",
       "         [0.3801],\n",
       "         [6.4359],\n",
       "         [2.1436],\n",
       "         [5.2343],\n",
       "         [1.1127],\n",
       "         [1.7208],\n",
       "         [3.5446]])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用框架现有的API来读取数据\n",
    "def load_array(data_arrays,batch_size,is_train=True):\n",
    "    \"\"\"构造一个Pytorch数据迭代器\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays) # dataset相当于Pytorch的Dataset。一个星号*，表示对list解开入参。      \n",
    "    return data.DataLoader(dataset,batch_size,shuffle=is_train) # 返回的是从dataset中随机挑选出batch_size个样本出来     \n",
    "\n",
    "batch_size = 10\n",
    "data_iter = load_array((features,labels),batch_size) # 返回的数据的迭代器\n",
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c6012b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "使用框架的预定义好的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c54a1a",
   "metadata": {
    "origin_pos": 20,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf96a4d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31716c55",
   "metadata": {
    "origin_pos": 29,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c01887",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "计算均方误差使用的是`MSELoss`类，也称为平方$L_2$范数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19a417ac",
   "metadata": {
    "origin_pos": 41,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68315d47",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "实例化一个`SGD`实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ae0989f",
   "metadata": {
    "origin_pos": 50,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5991157",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "训练过程代码与我们从零开始实现时所做的非常相似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1270d706",
   "metadata": {
    "origin_pos": 55,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000218\n",
      "epoch 2, loss 0.000109\n",
      "epoch 3, loss 0.000110\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter: # 从DataLoader里面一次一次把所有数据拿出来\n",
    "        l = loss(net(X),y) # net(X) 为计算出来的线性回归的预测值\n",
    "        trainer.zero_grad() # 梯度清零\n",
    "        l.backward()\n",
    "        trainer.step()  # SGD优化器优化模型\n",
    "    l = loss(net(features), labels)\n",
    "    print(f'epoch {epoch + 1}, loss {l:f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8e4f61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "比较生成数据集的真实参数和通过有限数据训练获得的模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa7cef5a",
   "metadata": {
    "origin_pos": 60,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w的估计误差： tensor([-0.0019, -0.0006])\n",
      "b的估计误差： tensor([-9.9182e-05])\n"
     ]
    }
   ],
   "source": [
    "w = net[0].weight.data\n",
    "print('w的估计误差：', true_w - w.reshape(true_w.shape))\n",
    "b = net[0].bias.data\n",
    "print('b的估计误差：', true_b - b)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "required_libs": [],
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
