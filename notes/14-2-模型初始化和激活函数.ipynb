{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75bcd2fb",
   "metadata": {},
   "source": [
    "# 本节内容摘要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ec9e47",
   "metadata": {},
   "source": [
    "#### 2.1 让训练更加稳定\n",
    "\n",
    "我们的一个核心目标是如何让训练更稳定，梯度值不要太大也不要太小\n",
    "\n",
    "- 目标：让梯度值在合理的范围内\n",
    "  - 例如 [1e-6, 1e3]\n",
    "- 常用方法：\n",
    "  - 将乘法变加法（后面详细讲）：\n",
    "    - ResNet（跳跃连接，如果很多层，加入加法进去）\n",
    "    - LSTM（引入记忆细胞，更新门，遗忘门，通过门权重求和，控制下一步是否更新）\n",
    "  - 归一化（后面详细讲）：\n",
    "    - 梯度归一化（归一化均值，方差）\n",
    "    - 梯度裁剪(clipping)：比如大于/小于一个固定的阈值，就让梯度等于这个阈值，将梯度限制在一个范围中。（可以缓解梯度爆炸）\n",
    "  - **合理的权重初始和激活函数**：本节课讲述重点\n",
    "\n",
    "\n",
    "#### 2.2 基本假设：让每层的均值/方差是一个常数\n",
    "\n",
    "- **将每层的输出和梯度都看做随机变量**\n",
    "\n",
    "  比如第i层有100维，就将输出和梯度分别看成100个随机变量\n",
    "\n",
    "- **让它们的均值和方差都保持一致**\n",
    "\n",
    "  我们的目标，这样不管神经网络多深，最后一层总与第一层差不多，从而不会梯度爆炸和消失\n",
    "\n",
    "#### 2.3 权重初始化\n",
    "\n",
    "- 在合理值区间里随机初始参数\n",
    "- 训练**开始**的时候更容易有数值不稳定\n",
    "  - 远离最优解的地方损失函数表面可能很复杂\n",
    "  - 最优解附近表面会比较平\n",
    "- 使用N(0, 0.01)分布来初始可能对小网络没问题，但不能保证深度神经网络\n",
    "\n",
    "#### 2.4 例子：MLP\n",
    "\n",
    "下面我们以MLP为例，考虑需要什么条件，才能满足【让每层的均值/方差是一个常数】的假设。\n",
    "\n",
    "##### 2.4.1 模型假设\n",
    "\n",
    "- 每一层**权重**中的变量均为**独立同分布**，并设出均值、方差。\n",
    "- 每一层**输入**的变量**独立于**该层**权重**变量。同时**输入变量**之间**独立同分布**。\n",
    "- 假设没有激活函数(先简化分析，之后会考虑有激活函数的情况)，可以求得该层输出的期望为0。\n",
    "\n",
    "\n",
    "此处用到了一个重要性质\n",
    "\n",
    "\n",
    "##### 2.4.2 正向方差\n",
    "\n",
    "\n",
    "##### 2.4.3 反向均值和方差\n",
    "\n",
    "\n",
    "##### 2.4.4 Xavier初始\n",
    "常用的权重初始化方法\n",
    "\n",
    "\n",
    "##### 2.4.5 假设线性的激活函数\n",
    "\n",
    "真实情况下，我们并不会用线性的激活函数（这样相当于没有进行激活），这里为了简化问题，假设激活函数是线性的。\n",
    "\n",
    "- **正向**\n",
    "\n",
    "- **反向**\n",
    "\n",
    "**通过正向和反向的推导，我们可以得出的【结论】是：当激活函数为f(x)=x，这种恒等映射更有利于维持神经网络的稳定性。**\n",
    "\n",
    "##### 2.4.6 检查常用激活函数\n",
    "\n",
    "对于常用激活函数：tanh，relu满足在零点附近有f(x)=x，而sigmoid函数在零点附近不满足要求，可以对sigmoid函数进行调整（根据Taylor展开式，调整其过原点）\n",
    "\n",
    "### 2.5 总结\n",
    "\n",
    "- 合理的权重初始值(如Xavier)和激活函数的选取(如relu, tanh, 调整后的sigmoid)可以提升数值稳定性。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc6b136",
   "metadata": {},
   "source": [
    "# 讲义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68b113df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1100\"\n",
       "            height=\"600\"\n",
       "            src=\"../PPT/part-0_19.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1104db640>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, IFrame\n",
    "\n",
    "# 使用IFrame将PDF文件嵌入到Notebook中\n",
    "pdf_path = \"../PPT/part-0_19.pdf\"\n",
    "display(IFrame(pdf_path, width=1100, height=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2743c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
